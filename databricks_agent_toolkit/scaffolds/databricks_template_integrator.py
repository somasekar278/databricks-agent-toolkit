"""
Databricks App Template Integrator

Integrates official Databricks app templates (Streamlit, Gradio, Dash) with agent generation.
Avoids custom frontend generation - uses battle-tested Databricks templates.
"""

import shutil
from pathlib import Path
from typing import Any, Dict


class DatabricksTemplateIntegrator:
    """Integrate official Databricks app templates."""

    # Map UI framework to template directory
    TEMPLATE_MAP = {
        "streamlit": "e2e-chatbot-app",
        "gradio": "gradio-chatbot-app",
        "dash": "dash-chatbot-app",
    }

    def __init__(self):
        # Try local dev path first
        self.templates_root = Path(__file__).parent.parent.parent / "databricks-app-templates-research"

        # If not found (installed package), use user's home directory cache
        if not self.templates_root.exists():
            self.templates_root = Path.home() / ".databricks-agent-toolkit" / "templates"

            # Auto-clone if not exists
            if not self.templates_root.exists():
                print("ðŸ“¥ Downloading Databricks app templates (first time only)...")
                self._clone_templates()

    def _clone_templates(self) -> None:
        """Clone Databricks templates repo to local cache."""
        import subprocess

        cache_dir = Path.home() / ".databricks-agent-toolkit"
        cache_dir.mkdir(parents=True, exist_ok=True)

        try:
            subprocess.run(
                [
                    "git",
                    "clone",
                    "--depth",
                    "1",
                    "https://github.com/databricks/app-templates.git",
                    str(self.templates_root),
                ],
                check=True,
                capture_output=True,
            )
            print(f"âœ… Templates downloaded to: {self.templates_root}")
        except subprocess.CalledProcessError as e:
            raise RuntimeError(
                f"Failed to clone templates: {e.stderr.decode()}\n"
                "Please clone manually: git clone https://github.com/databricks/databricks-app-templates.git "
                f"{self.templates_root}"
            )

    def get_template_path(self, ui_framework: str) -> Path:
        """Get the template directory path for a UI framework."""
        template_name = self.TEMPLATE_MAP.get(ui_framework)
        if not template_name:
            raise ValueError(f"Unsupported UI framework: {ui_framework}. Choose from: {list(self.TEMPLATE_MAP.keys())}")

        template_path = self.templates_root / template_name
        if not template_path.exists():
            raise FileNotFoundError(f"Template not found: {template_path}")

        return template_path

    def copy_template(self, ui_framework: str, output_dir: Path) -> None:
        """Copy the official Databricks template to output directory."""
        template_path = self.get_template_path(ui_framework)

        print(f"ðŸ“¦ Using official Databricks template: {template_path.name}")

        # Warn about streaming support
        if ui_framework in ["gradio", "dash"]:
            print(f"âš ï¸  Note: {ui_framework.capitalize()} template does not support streaming responses")
            print("   Responses will be batch-only. For streaming, use --ui streamlit")

        # Copy entire template directory
        shutil.copytree(template_path, output_dir, dirs_exist_ok=True)

        # Remove .git if exists (don't want nested git repos)
        git_dir = output_dir / ".git"
        if git_dir.exists():
            shutil.rmtree(git_dir)

        # Add databricks.yml if not present (for Asset Bundle deployment)
        if not (output_dir / "databricks.yml").exists():
            self._create_databricks_yml(output_dir)

    def _create_databricks_yml(self, output_dir: Path) -> None:
        """Create databricks.yml for Asset Bundle deployment."""
        app_name = output_dir.name
        databricks_yml = f"""bundle:
  name: {app_name}

resources:
  apps:
    {app_name}:
      name: {app_name}
      description: "Generated by Databricks Agent Toolkit"
      source_code_path: .
      permissions:
        - level: CAN_MANAGE
          user_name: ${{workspace.current_user.userName}}

targets:
  dev:
    mode: development
    default: true
    workspace:
      root_path: /Users/${{workspace.current_user.userName}}/.bundle/${{bundle.name}}/${{bundle.target}}
"""
        (output_dir / "databricks.yml").write_text(databricks_yml)
        print("âœ… Added databricks.yml for Asset Bundle deployment")

    def customize_template(self, output_dir: Path, options: Dict[str, Any]) -> None:
        """Customize the template with user options (model endpoint, etc)."""
        ui = options.get("ui", "streamlit")
        model = options.get("model", "databricks-claude-sonnet-4")
        level = options.get("level", "chatbot")

        print(f"ðŸ”§ Customizing {ui} template for {level}...")

        # 1. Update app.yaml with model endpoint
        self._update_app_yaml(output_dir, model)

        # 2. Suppress noisy logs from libraries
        self._suppress_debug_logs(output_dir, ui)

        # 3. Strip L2 features if generating L1
        if level == "chatbot":
            self._strip_memory_features(output_dir, ui)

        # 4. Update README
        self._update_readme(output_dir, ui, model, level)

        print(f"âœ… Template customized for model: {model}")

    def _update_app_yaml(self, output_dir: Path, model: str) -> None:
        """Update app.yaml with the correct model endpoint."""
        app_yaml_path = output_dir / "app.yaml"
        if not app_yaml_path.exists():
            return

        content = app_yaml_path.read_text()

        # Replace SERVING_ENDPOINT configuration
        if 'valueFrom: "serving-endpoint"' in content:
            # Replace resource reference with direct value
            content = content.replace('valueFrom: "serving-endpoint"', f'value: "{model}"')
            app_yaml_path.write_text(content)
            print(f"âœ… Configured SERVING_ENDPOINT: {model}")
        elif "SERVING_ENDPOINT" in content:
            print("âš ï¸  SERVING_ENDPOINT found but in unexpected format")
            print(f"   Manually set to: {model}")

    def _suppress_debug_logs(self, output_dir: Path, ui: str) -> None:
        """Suppress noisy DEBUG logs from Databricks SDK and other libraries."""
        if ui != "streamlit":
            return  # Only implemented for Streamlit for now

        app_py_path = output_dir / "app.py"
        if not app_py_path.exists():
            return

        content = app_py_path.read_text()

        # Add logging suppression after logger initialization
        logging_config = """
# Suppress verbose logs from Databricks SDK and other libraries
logging.getLogger("databricks.sdk").setLevel(logging.WARNING)
logging.getLogger("urllib3").setLevel(logging.WARNING)
logging.getLogger("watchdog").setLevel(logging.WARNING)
"""

        if "databricks.sdk" not in content and "logger = logging.getLogger(__name__)" in content:
            content = content.replace(
                "logger = logging.getLogger(__name__)", f"logger = logging.getLogger(__name__){logging_config}"
            )
            app_py_path.write_text(content)
            print("âœ… Suppressed noisy DEBUG logs")

    def _strip_memory_features(self, output_dir: Path, ui: str) -> None:
        """Remove memory-related UI components for L1 chatbots."""
        # TODO: Implement UI-specific stripping
        # For Streamlit: Remove session history sidebar, clear history button
        # For Dash: Remove conversation history panel
        # For Gradio: Remove chat history component
        print("âš ï¸  Memory features not stripped yet (template may show extra UI)")
        print("   L1 apps will work but may have unused UI elements")

    def _update_readme(self, output_dir: Path, ui: str, model: str, level: str) -> None:
        """Update or create README with generation info."""
        readme_path = output_dir / "README.md"
        readme_content = f"""# {output_dir.name}

Generated using **Databricks Agent Toolkit** with official {ui.capitalize()} template.

**Level**: {level.upper()}
**Model**: `{model}`
**UI Framework**: {ui.capitalize()}

## Quick Start

1. **Deploy to Databricks**:
   ```bash
   databricks bundle deploy
   databricks bundle run
   ```

2. **View in Databricks Apps UI**

3. **Configure Model Endpoint**:
   - Update `app.yaml` to set `SERVING_ENDPOINT` to your model endpoint name
   - Or use Databricks Apps resources to auto-configure

## Architecture

- **UI**: Official Databricks {ui.capitalize()} template
- **Backend**: Databricks Model Serving endpoint
- **Features**: {'Basic chat (no memory)' if level == 'chatbot' else 'Chat with memory & RAG'}

"""  # nosec B608

        # Append original README if exists
        if readme_path.exists():
            original = readme_path.read_text()
            readme_content += f"\n---\n\n## Original Template README\n\n{original}"

        readme_path.write_text(readme_content)

    def integrate_rag(self, output_dir: Path, rag_config: Dict[str, Any]) -> None:
        """Add RAG capabilities to the template (for L2+)."""
        vector_store = rag_config.get("vector_store", "lakebase")
        ui = rag_config.get("ui", "streamlit")

        print(f"ðŸ§  Integrating RAG with {vector_store} vector store...")

        # Only Streamlit is supported for now
        if ui != "streamlit":
            print(f"âš ï¸  RAG not yet supported for {ui} - only Streamlit")
            return

        # 1. Copy RAG modules
        self._copy_rag_modules(output_dir)

        # 2. Inject RAG logic into app.py
        self._inject_rag_into_streamlit(output_dir, vector_store)

        # 3. Add vector store config to app.yaml
        if vector_store == "lakebase":
            self._add_lakebase_env_vars(output_dir)

        # 4. Add RAG dependencies
        self._add_rag_dependencies(output_dir)

        # 5. Copy config.yaml
        self._copy_rag_config(output_dir, rag_config)

        print("âœ… RAG integration complete")

    def _copy_rag_modules(self, output_dir: Path) -> None:
        """Copy and render RAG modules to the output directory."""
        templates_dir = Path(__file__).parent / "templates" / "rag_chatbot"

        rag_files = [
            # Core RAG components
            "lakebase_retriever.py.jinja2",
            "embeddings.py.jinja2",
            
            # Quick start (testing)
            "setup_sample_data.py.jinja2",      # Quick: Direct to Lakebase
            "generate_sample_docs.py.jinja2",   # Full pipeline: Creates .txt files
            
            # Production ingestion pipeline (DABs)
            "data_ingestion_job.py.jinja2",
            "databricks_rag.yml.jinja2",  # Complete DABs: Volume, Lakebase, Synced Table, Job, App
            
            # Documentation
            "RAG_COMPLETE_GUIDE.md.jinja2",
        ]

        for file_name in rag_files:
            src = templates_dir / file_name
            if not src.exists():
                print(f"âš ï¸  Template not found: {src}")
                continue

            # Remove .jinja2 extension
            dest_name = file_name.replace(".jinja2", "")
            dest = output_dir / dest_name

            # Render Jinja2 template if needed
            content = src.read_text()
            if "{{" in content or "{%" in content:
                # Get context from existing config
                context = self._get_rag_context(output_dir)
                from jinja2 import Template
                template = Template(content)
                rendered = template.render(**context)
                dest.write_text(rendered)
                print(f"âœ… Rendered {dest_name}")
            else:
                shutil.copy(src, dest)
                print(f"âœ… Added {dest_name}")

    def _get_rag_context(self, output_dir: Path) -> Dict[str, Any]:
        """Extract context for rendering RAG templates."""
        import yaml
        
        # Try to get name from directory
        name = output_dir.name
        
        # Try to get config from config.yaml
        config_path = output_dir / "config.yaml"
        if config_path.exists():
            with open(config_path) as f:
                config = yaml.safe_load(f)
                rag_config = config.get("rag", {})
        else:
            rag_config = {}
        
        # Build context for Jinja2
        return {
            "name": name,
            "rag": rag_config,
        }

    def _inject_rag_into_streamlit(self, output_dir: Path, vector_store: str) -> None:
        """Inject RAG logic into Streamlit app.py."""
        app_py_path = output_dir / "app.py"
        if not app_py_path.exists():
            print("âš ï¸  app.py not found, skipping RAG injection")
            return

        content = app_py_path.read_text()

        # Add RAG imports
        rag_imports = """from lakebase_retriever import LakebaseRetriever
from embeddings import EmbeddingGenerator
"""

        if "from lakebase_retriever import" not in content:
            # Add after existing imports
            content = content.replace(
                "from collections import OrderedDict",
                f"from collections import OrderedDict\n{rag_imports}",
            )

        # Initialize RAG components after SERVING_ENDPOINT check
        rag_init = """
# Initialize RAG components
try:
    embedding_generator = EmbeddingGenerator()
    retriever = LakebaseRetriever()
    print("âœ… RAG initialized (Lakebase pgvector)")
except Exception as e:
    print(f"âš ï¸  RAG initialization failed: {e}")
    print("   Falling back to non-RAG mode")
    embedding_generator = None
    retriever = None
"""

        if "embedding_generator = EmbeddingGenerator()" not in content:
            content = content.replace(
                "ENDPOINT_SUPPORTS_FEEDBACK = endpoint_supports_feedback(SERVING_ENDPOINT)",
                f"ENDPOINT_SUPPORTS_FEEDBACK = endpoint_supports_feedback(SERVING_ENDPOINT)\n{rag_init}",
            )

        # Inject RAG retrieval before LLM call
        rag_retrieval = """
    # RAG: Retrieve relevant documents and augment prompt
    if retriever and embedding_generator:
        try:
            # Generate embedding for user query
            query_embedding = embedding_generator.generate_embedding(prompt)

            # Retrieve similar documents
            context_docs = retriever.retrieve(query_embedding)

            if context_docs:
                print(f"ðŸ“š Retrieved {len(context_docs)} relevant documents")

                # Build context from retrieved docs
                context_text = "\\n\\n".join([
                    f"[Document {i+1}]\\n{doc['content']}"
                    for i, doc in enumerate(context_docs)
                ])

                # Augment prompt with context
                augmented_prompt = f\"\"\"Context information:
{context_text}

User question: {prompt}

Please answer based on the context provided above.\"\"\"

                # Replace original prompt with augmented one
                prompt = augmented_prompt
        except Exception as e:
            print(f"âš ï¸  RAG retrieval failed: {e}")
            # Continue without RAG

"""

        # Inject before the user message is added to history
        if "# RAG: Retrieve relevant documents" not in content:
            # Find where we add user message to history
            if "user_msg = UserMessage(content=prompt)" in content:
                content = content.replace(
                    "# Add user message to chat history\n    user_msg = UserMessage(content=prompt)",
                    f"{rag_retrieval}    # Add user message to chat history\n    user_msg = UserMessage(content=prompt)",
                )

        app_py_path.write_text(content)
        print("âœ… Injected RAG logic into app.py")

    def _add_lakebase_env_vars(self, output_dir: Path) -> None:
        """Add Lakebase environment variables to app.yaml."""
        app_yaml_path = output_dir / "app.yaml"
        if not app_yaml_path.exists():
            print("âš ï¸  app.yaml not found, skipping Lakebase config")
            return

        content = app_yaml_path.read_text()

        # Add Lakebase env vars for RAG (no literal credentials; use Apps UI or secrets)
        lakebase_env = """  # Lakebase: set in Databricks Apps UI or via secrets; never commit real values
  - name: "LAKEBASE_HOST"
    value: ""  # Or use secret reference
  - name: "LAKEBASE_DATABASE"
    value: "rag"
  - name: "LAKEBASE_USER"
    value: ""
  - name: "LAKEBASE_PASSWORD"
    value: ""  # Use Databricks secrets in production
  - name: "PGSSLMODE"
    value: "require"
  - name: "PGCHANNELBINDING"
    value: "prefer"
  - name: "EMBEDDING_ENDPOINT"
    value: "databricks-bge-large-en"
"""

        # Add after SERVING_ENDPOINT
        if "LAKEBASE_HOST" not in content:
            # Append to the end of env section (or end of file)
            if not content.endswith("\n"):
                content += "\n"
            content += lakebase_env
            app_yaml_path.write_text(content)
            print("âœ… Added Lakebase configuration to app.yaml")
            print("âš ï¸  Update app.yaml with your Lakebase credentials")

    def _add_rag_dependencies(self, output_dir: Path) -> None:
        """Add RAG dependencies to requirements.txt."""
        req_path = output_dir / "requirements.txt"
        if not req_path.exists():
            print("âš ï¸  requirements.txt not found")
            return

        content = req_path.read_text()

        rag_deps = "\n# RAG dependencies\npsycopg2-binary>=2.9.9\npgvector>=0.2.5\n"

        if "psycopg2-binary" not in content:
            content += rag_deps
            req_path.write_text(content)
            print("âœ… Added RAG dependencies to requirements.txt")

    def _copy_rag_config(self, output_dir: Path, rag_config: Dict[str, Any]) -> None:
        """Copy and customize config.yaml for RAG."""
        templates_dir = Path(__file__).parent / "templates" / "rag_chatbot"
        config_template = templates_dir / "config.yaml.jinja2"

        if not config_template.exists():
            print("âš ï¸  config.yaml.jinja2 not found")
            return

        # Render config template
        from jinja2 import Template

        template = Template(config_template.read_text())
        rendered = template.render(name=output_dir.name, model=rag_config.get("model", "databricks-claude-sonnet-4"))

        config_path = output_dir / "config.yaml"
        config_path.write_text(rendered)
        print("âœ… Added config.yaml")


def generate_with_databricks_template(name: str, level: str, options: Dict[str, Any], output_dir: str) -> Path:
    """
    Generate an agent app using official Databricks templates.

    Args:
        name: App name
        level: Agent level (chatbot, assistant, etc.)
        options: Generation options (model, ui, streaming, etc.)
        output_dir: Output directory path

    Returns:
        Path to generated app
    """
    integrator = DatabricksTemplateIntegrator()
    ui = options.get("ui", "streamlit")
    output_path = Path(output_dir)

    # Copy the official template
    integrator.copy_template(ui, output_path)

    # Add level to options for customization
    options_with_level = {**options, "level": level}

    # Customize with user options
    integrator.customize_template(output_path, options_with_level)

    # Add RAG if enabled
    if options.get("enable_rag"):
        rag_config = {
            "vector_store": options.get("vector_store", "lakebase"),
            "ui": ui,
            "model": options.get("model", "databricks-claude-sonnet-4"),
        }
        integrator.integrate_rag(output_path, rag_config)

    return output_path
