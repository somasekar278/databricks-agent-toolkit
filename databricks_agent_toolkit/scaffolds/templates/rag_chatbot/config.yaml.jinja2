# RAG Chatbot Configuration
# Generated by Databricks Agent Toolkit

# Model Configuration
model:
  endpoint: "{{ model }}"
  temperature: 0.7
  max_tokens: 2000

# RAG Configuration
rag:
  enabled: true
  vector_store: "lakebase"  # or "databricks" for Databricks Vector Search
  
  # Data Ingestion (UC Volume → Delta → Lakebase)
  ingestion:
    uc_volume_path: "/Volumes/main/default/{{ name }}_docs"  # UC Volume for raw documents
    delta_table: "main.default.{{ name }}_embeddings"  # Delta table for embeddings
    
    # Schedule configuration (Quartz Cron format)
    schedule:
      cron: "0 0 0 * * ?"  # Daily at midnight UTC
      timezone: "UTC"
      pause_on_deploy: true  # Start paused, manually enable after testing
    
    # Common schedules:
    # "0 0 0 * * ?"     - Daily at midnight
    # "0 0 2 * * ?"     - Daily at 2 AM
    # "0 0 0 * * MON"   - Weekly on Monday at midnight
    # "0 0 0 1 * ?"     - Monthly on 1st at midnight
    # "0 0 */6 * * ?"   - Every 6 hours
  
  # Lakebase pgvector settings (Provisioned instance)
  lakebase:
    instance_name: "{{ name }}-lakebase"  # Created via DABs
    catalog_name: "{{ name }}_lakebase_catalog"  # Unity Catalog mapping
    database: "rag_db"  # Postgres database name
    table: "embeddings"  # Synced from Delta via synced_database_tables
    capacity: "CU_1"  # Start with 1 CU, scale as needed (CU_1, CU_2, CU_4, CU_8)
    top_k: 5
    index_type: "hnsw"  # "hnsw" (matches Databricks) or "ivfflat" (faster build)
  
  # Embedding model (Foundation Model APIs)
  embedding:
    endpoint: "databricks-bge-large-en"  # BGE-large English embedding model
    dimension: 1024
  
  # Document chunking (ai_parse settings)
  chunking:
    chunk_size: 512
    overlap: 50

# MLflow Configuration
mlflow:
  experiment: "/Shared/{{ name }}"
  auto_trace: true
